{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Bert Model:\n",
        "Bert model is a transformer based model which uses self attention layer.\n",
        "It is used to convert words into vectors in such a way so that their semantic and contextual meaning is preserved.\n",
        "before applying the bert model, we have to pre process the data to be able to feed that data into the bert model."
      ],
      "metadata": {
        "id": "Jg8m0bkeccG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the dependencies\n",
        "#!pip install tensorflow_hub\n",
        "#!pip install tensorflow_text\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noz7_DSSeGKH",
        "outputId": "9ff017e0-d965-45e3-f586-42756e5a8354"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: tensorflow_text\n",
            "Successfully installed tensorflow_text-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different versions of the BERT model can be downloaded from the tensorflow hub website.\n",
        "https://tfhub.dev/google/collections/bert/1"
      ],
      "metadata": {
        "id": "nV_ZaFJEjznM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_url='https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "encoder_url='https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'"
      ],
      "metadata": {
        "id": "GTbd9Lp2hH-I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocessed_model=hub.KerasLayer(preprocessed_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLPhV75H9nO6",
        "outputId": "49b57d0d-7426-4945-d32c-3ea684cbcfc4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=['Nice Movie Indeed','I love Deep Learning']"
      ],
      "metadata": {
        "id": "H3ZOA5N0-Ydk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing model:\n",
        "This is used to convert text into a certain format so that can be processed by the bert model. it automatically converts words into vectors by applying several prprocessing steps.\n",
        "this preprocessing involves:\n",
        "\n",
        "a) tokenization\n",
        "\n",
        "b) adding tokens to mark the beginning and ending of the sentences.\n",
        "\n",
        "c) Padding\n",
        "\n",
        "d) assigning unique integer id to each word."
      ],
      "metadata": {
        "id": "-ONc4-UiBPxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output=bert_preprocessed_model(text)"
      ],
      "metadata": {
        "id": "PuHFM_m6-iDt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2tM5LHo-4xP",
        "outputId": "c7ef143f-dd4a-42e2-ed7a-af48a21bdc9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3pcuur-_Gnq",
        "outputId": "760614fb-ccff-49eb-c2b5-5ef5ccbc5cba"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_type_ids', 'input_word_ids', 'input_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output['input_mask'] # it adds two more tokens to the beginning and the end of the sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MelImdU_IVA",
        "outputId": "aa3d4814-6e9a-4813-88b0-408992732970"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output['input_word_ids'] # assigning the index to each word in the vocabulary."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzP-lal4Bw-9",
        "outputId": "f8614f35-c845-47b0-bee0-d143606306f5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
              "array([[ 101, 3835, 3185, 5262,  102,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0],\n",
              "       [ 101, 1045, 2293, 2784, 4083,  102,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bert Encoder:\n",
        "now we can use the encoder after processing the input."
      ],
      "metadata": {
        "id": "uY0TKuyxEvXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model=hub.KerasLayer(encoder_url)"
      ],
      "metadata": {
        "id": "cMnTy4_9CYkh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_output=bert_model(output)"
      ],
      "metadata": {
        "id": "KeT3rTmTFJ1S"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_output.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoXNmIPGFPQI",
        "outputId": "4af602be-22d7-4e6e-fde4-d48e3fc27bb8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['sequence_output', 'pooled_output', 'encoder_outputs', 'default'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Examining the output of the bert model\n",
        "bert_output['pooled_output']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCzxRhQbFqyz",
        "outputId": "aeab8419-a9db-4412-e78c-f72b16287076"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
              "array([[-0.791774  , -0.21411902,  0.49769545, ...,  0.24465242,\n",
              "        -0.47334465,  0.8175868 ],\n",
              "       [-0.7819546 , -0.20902902,  0.5304151 , ...,  0.31390852,\n",
              "        -0.60525256,  0.8173208 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pooled_output vs Sequence_Output:\n",
        "Pooled_output gives the embedding of the whole sentence. Whereas, Sequence_output gives the embedding of each word."
      ],
      "metadata": {
        "id": "FyOBPG5eIHVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_output['sequence_output']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeTcHi0xGnJF",
        "outputId": "e08c1038-0e75-4162-d736-944e37fa78a0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128, 768), dtype=float32, numpy=\n",
              "array([[[ 7.2920412e-02,  8.5678160e-02,  1.4476837e-01, ...,\n",
              "         -9.6770801e-02,  8.7221146e-02,  7.7111028e-02],\n",
              "        [ 1.7839377e-01, -1.9006082e-01,  5.0349444e-01, ...,\n",
              "         -5.8698267e-02,  3.2717147e-01, -1.5578502e-01],\n",
              "        [ 1.8701456e-01, -4.3388769e-01, -4.8875162e-01, ...,\n",
              "         -1.5502810e-01,  1.4513135e-03, -2.4470958e-01],\n",
              "        ...,\n",
              "        [ 1.2083077e-01,  1.2884237e-01,  4.6453524e-01, ...,\n",
              "          7.3755175e-02,  1.7441934e-01,  1.6522089e-01],\n",
              "        [ 7.9678386e-02, -1.1906989e-02,  5.0225419e-01, ...,\n",
              "          1.3777757e-01,  2.1002182e-01,  6.2461002e-03],\n",
              "        [-7.2127059e-02, -2.8303489e-01,  5.9033322e-01, ...,\n",
              "          4.7551912e-01,  1.6668460e-01, -8.9203194e-02]],\n",
              "\n",
              "       [[ 9.3838871e-02,  2.9481417e-02, -4.5924336e-02, ...,\n",
              "         -9.9129155e-02,  3.3907592e-05,  2.1539062e-01],\n",
              "        [ 7.6166362e-01, -3.7808530e-02,  4.7379714e-02, ...,\n",
              "         -5.5204666e-01,  5.2730739e-01,  1.9011682e-01],\n",
              "        [ 1.1957076e+00,  7.6431847e-01,  6.4289755e-01, ...,\n",
              "         -2.0989737e-01,  2.3694091e-01,  1.4743457e-02],\n",
              "        ...,\n",
              "        [ 2.6908822e-02,  5.7976648e-02,  3.0604970e-01, ...,\n",
              "          3.5986286e-01, -3.0976900e-01,  3.1076390e-02],\n",
              "        [-4.4886846e-02,  1.7483898e-02,  2.6701570e-01, ...,\n",
              "          3.3876646e-01, -3.5032058e-01,  3.9527558e-02],\n",
              "        [-1.3343862e-01, -4.1871939e-02,  2.7634442e-01, ...,\n",
              "          3.7088710e-01, -4.2542747e-01,  1.9337233e-02]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(bert_output['encoder_outputs'])\n",
        "# This length is 12 because we are using bert base model in which there are 12 encoders."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYeKE-fLIqYp",
        "outputId": "5bb771b9-6290-4c41-8c82-90dcdf2205b0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AlQjFlKLIz-U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}